{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7083baf0-a9ab-4b98-8e90-299b13abbc0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b020308-2cc7-4581-a828-e8c57a3216f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylib.data import my_dataloader, my_dataset, my_preprocess\n",
    "from mylib.classification import classification\n",
    "from mylib.classification.models import my_cnn, my_model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb5877-ee05-4029-90a9-1106b91b5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a1b64-830c-45bf-8127-239794c984a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from functools import partialmethod\n",
    "\n",
    "tqdm.__init__ = partialmethod(tqdm.__init__, disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe015a26-1bd6-4c86-8560-a6435316feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Torch version:  {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"device name:    {torch.cuda.get_device_name()}\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181f9b06-20b8-43a9-9a1a-41e9c2161821",
   "metadata": {},
   "source": [
    "## I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88873f-c480-46d5-b466-fe8a66f1a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path  = \"data/images\"\n",
    "label_path  = \"data/labels/label_v2.xlsx\"\n",
    "output_path = \"outputs/02\"\n",
    "\n",
    "fname_key = \"fname\"\n",
    "label_key = \"pap2_groundtruth\"\n",
    "fold_key  = \"slide\"\n",
    "\n",
    "name_classes = ['positive','negative']\n",
    "num_classes  = len(name_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757222c5-2b0c-44eb-92d3-85270739864f",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01631c-cd9a-4e1a-bad0-c17d2a9169c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験のパラメータ\n",
    "num_epochs = 100\n",
    "image_size = 224\n",
    "batch_size = 16\n",
    "val_ratio  = 0.1\n",
    "lr = 1e-4  # 学習率\n",
    "\n",
    "# データ拡張\n",
    "# Normalize -> RandomFlip -> RandomAffine\n",
    "transforms = my_preprocess.getStandardTransforms()\n",
    "\n",
    "\n",
    "# 再学習レイヤー\n",
    "# レイヤーには名前がついているので，再学習させるレイヤーの名前をリストに追加する\n",
    "training_layers = ['fc']  # 全結合層のみ学習させる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e5ccc6-57da-4f2e-9c32-f19932c752c2",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d8096f-434a-44e8-af22-dbd987671fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのロード\n",
    "_images, _labels, _fnames, _folds = my_dataloader.loadData4(\n",
    "    image_path,\n",
    "    label_path,\n",
    "    fname_key = fname_key,\n",
    "    label_key = label_key,\n",
    "    fold_key  = fold_key,\n",
    "    resize    = image_size,\n",
    "    to_tensor = True\n",
    ")\n",
    "print(len(_fnames))\n",
    "\n",
    "\n",
    "# 不適切なデータを除去\n",
    "# 不適切なデータ：label=-1\n",
    "images, labels, fnames, folds = [], [], [], []\n",
    "for i in range(len(_images)):\n",
    "    if _labels[i] != -1:\n",
    "        images.append(_images[i])\n",
    "        labels.append(_labels[i])\n",
    "        fnames.append(_fnames[i])\n",
    "        folds.append(_folds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85509f7-e77a-46ad-bbf0-8e4867d4a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "dataset = my_dataset.MyDataset(images, labels, fnames, name_classes)\n",
    "\n",
    "# Leave-one-case-outマネージャーを作成\n",
    "managers = my_dataset.getLocoManager(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f3506-a32f-4751-a964-59f7c15a9400",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515f233-17cf-44c9-9c83-b4f2b4f99ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for manager in managers:  # このループが 1fold\n",
    "    fold_id, fold_name = manager['fold_id'], manager['fold_name']\n",
    "    print(f\"======== fold-id: {fold_id} / fold-name: {fold_name} ========\")\n",
    "    \n",
    "    # モデルを作成\n",
    "    model, params = my_cnn.build_ResNet50(num_classes=num_classes, training_layers=training_layers)\n",
    "    model.to(device)\n",
    "    model.apply(my_model_utils.resetWeights)  # 重みをリセット\n",
    "    \n",
    "    # データローダーを作成\n",
    "    loader = my_dataset.getLoader(dataset, manager, batch_size, val_ratio=val_ratio)\n",
    "    \n",
    "    # 損失関数\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # オプティマイザ\n",
    "    optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9)\n",
    "    \n",
    "    # スケジューラ\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "    \n",
    "    # 学習履歴保存用\n",
    "    history = dict()\n",
    "    history['train_loss'], history['valid_loss'], history['train_acc'], history['valid_acc'] = [], [], [], []\n",
    "    \n",
    "    # 学習\n",
    "    best_loss = 1000.0  # 最良のlossを保存\n",
    "    for epoch in range(1, num_epochs+1):  # このループが 1epoch\n",
    "        ep_loss, ep_acc = classification.train(\n",
    "            device = device,\n",
    "            model  = model,\n",
    "            train_loader = loader['train'],\n",
    "            valid_loader = loader['valid'],\n",
    "            num_classes  = num_classes,\n",
    "            criterion    = criterion,\n",
    "            optimizer    = optimizer,\n",
    "            scheduler    = scheduler,\n",
    "            transforms   = transforms,\n",
    "        )\n",
    "        \n",
    "        # 学習履歴の保存\n",
    "        history['train_loss'].append(ep_loss['train'])\n",
    "        history['valid_loss'].append(ep_loss['valid'])\n",
    "        history['train_acc'].append(ep_acc['train'])\n",
    "        history['valid_acc'].append(ep_acc['valid'])\n",
    "        \n",
    "        # 最良のlossの場合モデルを保存\n",
    "        if ep_loss['valid'] < best_loss:\n",
    "            torch.save(model.state_dict(), f\"{output_path}/tmp.pth\")\n",
    "            best_loss = ep_loss['valid']\n",
    "            \n",
    "        # ログ出力\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        log = f\"\\repoch {epoch}/{num_epochs} (lr={current_lr:.6f}): <train> loss={ep_loss['train']:.4f} acc={ep_acc['train']:.4f} <valid> loss={ep_loss['valid']:.4f} acc={ep_acc['valid']:.4f}\"\n",
    "        print(log, end=\"\")\n",
    "        \n",
    "    # チェックポイントを生成\n",
    "    model.load_state_dict(torch.load(f\"{output_path}/tmp.pth\"))  # 最良モデルをロード\n",
    "    torch.save(model.state_dict(), f\"{output_path}/ckpt/{fold_name}_model.pth\")\n",
    "    \n",
    "    # 学習履歴ファイルを生成\n",
    "    df_history = pd.DataFrame.from_dict(history)\n",
    "    df_history.to_excel(f\"{output_path}/history/{fold_name}_history.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
